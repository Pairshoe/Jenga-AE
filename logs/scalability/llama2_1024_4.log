[2025-05-11 22:50:11,239] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:50:11,784] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-05-11 22:50:11,806] [INFO] [runner.py:568:main] cmd = /root/miniconda3/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None src/experiment/scalability/time.py --model_name_or_path checkpoints/llama2 --predictor_path checkpoints/predictor --output_dir ./output/llama2_1024 --max_steps 2400 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 1 --save_strategy steps --save_steps 400 --save_total_limit 10 --learning_rate 2e-5 --weight_decay 0.0 --warmup_steps 20 --lr_scheduler_type constant_with_warmup --adam_beta1 0.9 --adam_beta2 0.95 --bf16 --model_max_length 1024 --flash_attention True --pool_size 64 --thresh 0.4 --deepspeed src/experiment/scalability/ds_config/stage2.json --gradient_checkpoint True
[2025-05-11 22:50:14,515] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:50:14,973] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2025-05-11 22:50:14,973] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2025-05-11 22:50:14,973] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2025-05-11 22:50:14,974] [INFO] [launch.py:163:main] dist_world_size=4
[2025-05-11 22:50:14,974] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2025-05-11 22:50:14,974] [INFO] [launch.py:253:main] process 68300 spawned with command: ['/root/miniconda3/bin/python', '-u', 'src/experiment/scalability/time.py', '--local_rank=0', '--model_name_or_path', 'checkpoints/llama2', '--predictor_path', 'checkpoints/predictor', '--output_dir', './output/llama2_1024', '--max_steps', '2400', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--save_strategy', 'steps', '--save_steps', '400', '--save_total_limit', '10', '--learning_rate', '2e-5', '--weight_decay', '0.0', '--warmup_steps', '20', '--lr_scheduler_type', 'constant_with_warmup', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--bf16', '--model_max_length', '1024', '--flash_attention', 'True', '--pool_size', '64', '--thresh', '0.4', '--deepspeed', 'src/experiment/scalability/ds_config/stage2.json', '--gradient_checkpoint', 'True']
[2025-05-11 22:50:14,975] [INFO] [launch.py:253:main] process 68301 spawned with command: ['/root/miniconda3/bin/python', '-u', 'src/experiment/scalability/time.py', '--local_rank=1', '--model_name_or_path', 'checkpoints/llama2', '--predictor_path', 'checkpoints/predictor', '--output_dir', './output/llama2_1024', '--max_steps', '2400', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--save_strategy', 'steps', '--save_steps', '400', '--save_total_limit', '10', '--learning_rate', '2e-5', '--weight_decay', '0.0', '--warmup_steps', '20', '--lr_scheduler_type', 'constant_with_warmup', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--bf16', '--model_max_length', '1024', '--flash_attention', 'True', '--pool_size', '64', '--thresh', '0.4', '--deepspeed', 'src/experiment/scalability/ds_config/stage2.json', '--gradient_checkpoint', 'True']
[2025-05-11 22:50:14,975] [INFO] [launch.py:253:main] process 68302 spawned with command: ['/root/miniconda3/bin/python', '-u', 'src/experiment/scalability/time.py', '--local_rank=2', '--model_name_or_path', 'checkpoints/llama2', '--predictor_path', 'checkpoints/predictor', '--output_dir', './output/llama2_1024', '--max_steps', '2400', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--save_strategy', 'steps', '--save_steps', '400', '--save_total_limit', '10', '--learning_rate', '2e-5', '--weight_decay', '0.0', '--warmup_steps', '20', '--lr_scheduler_type', 'constant_with_warmup', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--bf16', '--model_max_length', '1024', '--flash_attention', 'True', '--pool_size', '64', '--thresh', '0.4', '--deepspeed', 'src/experiment/scalability/ds_config/stage2.json', '--gradient_checkpoint', 'True']
[2025-05-11 22:50:14,976] [INFO] [launch.py:253:main] process 68303 spawned with command: ['/root/miniconda3/bin/python', '-u', 'src/experiment/scalability/time.py', '--local_rank=3', '--model_name_or_path', 'checkpoints/llama2', '--predictor_path', 'checkpoints/predictor', '--output_dir', './output/llama2_1024', '--max_steps', '2400', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--save_strategy', 'steps', '--save_steps', '400', '--save_total_limit', '10', '--learning_rate', '2e-5', '--weight_decay', '0.0', '--warmup_steps', '20', '--lr_scheduler_type', 'constant_with_warmup', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--bf16', '--model_max_length', '1024', '--flash_attention', 'True', '--pool_size', '64', '--thresh', '0.4', '--deepspeed', 'src/experiment/scalability/ds_config/stage2.json', '--gradient_checkpoint', 'True']
[2025-05-11 22:50:18,687] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:50:18,694] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:50:18,707] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:50:18,722] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:50:18,988] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-05-11 22:50:18,994] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-05-11 22:50:19,011] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-05-11 22:50:19,011] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-05-11 22:50:19,017] [INFO] [comm.py:637:init_distributed] cdb=None
total time: 846.8102416992188
total time: 1324.9517822265625
total time: 1324.4207763671875
total time: 1323.9346923828125
total time: 430.89935302734375
total time: 430.8096923828125
total time: 431.26202392578125
total time: 432.04937744140625
total time: 438.5583190917969
total time: 440.7754821777344
total time: 440.7138671875
total time: 439.1490478515625
total time: 442.6297607421875
total time: 443.4226379394531
total time: 444.0513916015625
total time: 443.421875
[2025-05-11 22:50:46,021] [INFO] [launch.py:348:main] Process 68300 exits successfully.
[2025-05-11 22:50:46,021] [INFO] [launch.py:348:main] Process 68303 exits successfully.
[2025-05-11 22:50:47,023] [INFO] [launch.py:348:main] Process 68301 exits successfully.
[2025-05-11 22:50:47,023] [INFO] [launch.py:348:main] Process 68302 exits successfully.
