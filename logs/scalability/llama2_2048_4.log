[2025-05-11 22:52:07,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:52:07,841] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-05-11 22:52:07,864] [INFO] [runner.py:568:main] cmd = /root/miniconda3/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None src/experiment/scalability/time.py --model_name_or_path checkpoints/llama2 --predictor_path checkpoints/predictor --output_dir ./output/llama2_2048 --max_steps 2400 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 1 --save_strategy steps --save_steps 400 --save_total_limit 10 --learning_rate 2e-5 --weight_decay 0.0 --warmup_steps 20 --lr_scheduler_type constant_with_warmup --adam_beta1 0.9 --adam_beta2 0.95 --bf16 --model_max_length 2048 --flash_attention True --pool_size 64 --thresh 0.4 --deepspeed src/experiment/scalability/ds_config/stage2.json --gradient_checkpoint True
[2025-05-11 22:52:10,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:52:11,035] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2025-05-11 22:52:11,036] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2025-05-11 22:52:11,036] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2025-05-11 22:52:11,036] [INFO] [launch.py:163:main] dist_world_size=4
[2025-05-11 22:52:11,036] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2025-05-11 22:52:11,036] [INFO] [launch.py:253:main] process 70768 spawned with command: ['/root/miniconda3/bin/python', '-u', 'src/experiment/scalability/time.py', '--local_rank=0', '--model_name_or_path', 'checkpoints/llama2', '--predictor_path', 'checkpoints/predictor', '--output_dir', './output/llama2_2048', '--max_steps', '2400', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--save_strategy', 'steps', '--save_steps', '400', '--save_total_limit', '10', '--learning_rate', '2e-5', '--weight_decay', '0.0', '--warmup_steps', '20', '--lr_scheduler_type', 'constant_with_warmup', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--bf16', '--model_max_length', '2048', '--flash_attention', 'True', '--pool_size', '64', '--thresh', '0.4', '--deepspeed', 'src/experiment/scalability/ds_config/stage2.json', '--gradient_checkpoint', 'True']
[2025-05-11 22:52:11,037] [INFO] [launch.py:253:main] process 70769 spawned with command: ['/root/miniconda3/bin/python', '-u', 'src/experiment/scalability/time.py', '--local_rank=1', '--model_name_or_path', 'checkpoints/llama2', '--predictor_path', 'checkpoints/predictor', '--output_dir', './output/llama2_2048', '--max_steps', '2400', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--save_strategy', 'steps', '--save_steps', '400', '--save_total_limit', '10', '--learning_rate', '2e-5', '--weight_decay', '0.0', '--warmup_steps', '20', '--lr_scheduler_type', 'constant_with_warmup', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--bf16', '--model_max_length', '2048', '--flash_attention', 'True', '--pool_size', '64', '--thresh', '0.4', '--deepspeed', 'src/experiment/scalability/ds_config/stage2.json', '--gradient_checkpoint', 'True']
[2025-05-11 22:52:11,037] [INFO] [launch.py:253:main] process 70770 spawned with command: ['/root/miniconda3/bin/python', '-u', 'src/experiment/scalability/time.py', '--local_rank=2', '--model_name_or_path', 'checkpoints/llama2', '--predictor_path', 'checkpoints/predictor', '--output_dir', './output/llama2_2048', '--max_steps', '2400', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--save_strategy', 'steps', '--save_steps', '400', '--save_total_limit', '10', '--learning_rate', '2e-5', '--weight_decay', '0.0', '--warmup_steps', '20', '--lr_scheduler_type', 'constant_with_warmup', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--bf16', '--model_max_length', '2048', '--flash_attention', 'True', '--pool_size', '64', '--thresh', '0.4', '--deepspeed', 'src/experiment/scalability/ds_config/stage2.json', '--gradient_checkpoint', 'True']
[2025-05-11 22:52:11,038] [INFO] [launch.py:253:main] process 70771 spawned with command: ['/root/miniconda3/bin/python', '-u', 'src/experiment/scalability/time.py', '--local_rank=3', '--model_name_or_path', 'checkpoints/llama2', '--predictor_path', 'checkpoints/predictor', '--output_dir', './output/llama2_2048', '--max_steps', '2400', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '1', '--save_strategy', 'steps', '--save_steps', '400', '--save_total_limit', '10', '--learning_rate', '2e-5', '--weight_decay', '0.0', '--warmup_steps', '20', '--lr_scheduler_type', 'constant_with_warmup', '--adam_beta1', '0.9', '--adam_beta2', '0.95', '--bf16', '--model_max_length', '2048', '--flash_attention', 'True', '--pool_size', '64', '--thresh', '0.4', '--deepspeed', 'src/experiment/scalability/ds_config/stage2.json', '--gradient_checkpoint', 'True']
[2025-05-11 22:52:14,729] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:52:14,749] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:52:14,764] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:52:14,773] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-11 22:52:15,026] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-05-11 22:52:15,064] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-05-11 22:52:15,073] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-05-11 22:52:15,073] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-05-11 22:52:15,085] [INFO] [comm.py:637:init_distributed] cdb=None
total time: 1619.139892578125
total time: 1618.20556640625
total time: 1621.4971923828125
total time: 1179.2432861328125
total time: 777.1696166992188
total time: 777.0035400390625total time: 777.1605834960938

total time: 777.8428344726562
total time: 779.6002807617188total time: 773.4758911132812total time: 779.7786254882812


total time: 779.8255615234375
total time: 779.454345703125
total time: 779.7529296875total time: 779.55908203125

total time: 780.106201171875
[2025-05-11 22:52:44,072] [INFO] [launch.py:348:main] Process 70769 exits successfully.
[2025-05-11 22:52:44,072] [INFO] [launch.py:348:main] Process 70770 exits successfully.
[2025-05-11 22:52:44,072] [INFO] [launch.py:348:main] Process 70768 exits successfully.
[2025-05-11 22:52:44,072] [INFO] [launch.py:348:main] Process 70771 exits successfully.
