original_num_embeddings: 2048
original_embed_positions: torch.Size([2050, 4096])
forward time: 1256.9833984375, backward time: 821.7681884765625, optimizer step time: 46.845951080322266, total time: 2125.5975379943848
forward time: 650.14111328125, backward time: 792.6005859375, optimizer step time: 4.348927974700928, total time: 1447.090627193451
forward time: 648.92333984375, backward time: 795.60498046875, optimizer step time: 4.520959854125977, total time: 1449.049280166626
forward time: 649.581298828125, backward time: 796.8204956054688, optimizer step time: 4.325376033782959, total time: 1450.7271704673767
