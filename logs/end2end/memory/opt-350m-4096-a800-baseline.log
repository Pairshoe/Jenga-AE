original_num_embeddings: 2048
original_embed_positions: torch.Size([2050, 1024])
[2025-05-05 23:27:44,437] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
before forward allocaiton: 641.79833984375, peak memory: 641.79833984375, reserve: 650.0
after forward allocaiton: 6662.10986328125, peak memory: 7054.83642578125, reserve: 7088.0
before backward allocaiton: 5108.65673828125, peak memory: 6662.10986328125, reserve: 7088.0
after backward allocaiton: 664.048828125, peak memory: 5893.919921875, reserve: 7088.0
before step allocaiton: 664.04931640625, peak memory: 664.0517578125, reserve: 7088.0
after step allocaiton: 676.04931640625, peak memory: 682.04931640625, reserve: 7094.0
{'loss': 4.0381, 'grad_norm': 2.611631393432617, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}
before forward allocaiton: 670.04931640625, peak memory: 676.04931640625, reserve: 7094.0
after forward allocaiton: 6682.23583984375, peak memory: 7074.96240234375, reserve: 7100.0
before backward allocaiton: 5128.78271484375, peak memory: 6682.23583984375, reserve: 7100.0
after backward allocaiton: 676.0498046875, peak memory: 5914.0458984375, reserve: 7100.0
before step allocaiton: 676.04931640625, peak memory: 676.05224609375, reserve: 7100.0
after step allocaiton: 676.04931640625, peak memory: 682.04931640625, reserve: 7100.0
{'loss': 4.4721, 'grad_norm': 2.9078054428100586, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
before forward allocaiton: 670.04931640625, peak memory: 676.04931640625, reserve: 7100.0
after forward allocaiton: 6682.23583984375, peak memory: 7074.96240234375, reserve: 7100.0
before backward allocaiton: 5128.78271484375, peak memory: 6682.23583984375, reserve: 7100.0
after backward allocaiton: 676.0498046875, peak memory: 5914.0458984375, reserve: 7100.0
before step allocaiton: 676.04931640625, peak memory: 676.05224609375, reserve: 7100.0
after step allocaiton: 676.04931640625, peak memory: 682.04931640625, reserve: 7100.0
{'loss': 4.7755, 'grad_norm': 1.9222670793533325, 'learning_rate': 3e-06, 'epoch': 0.0}
before forward allocaiton: 670.04931640625, peak memory: 676.04931640625, reserve: 7100.0
after forward allocaiton: 6682.23583984375, peak memory: 7074.96240234375, reserve: 7100.0
before backward allocaiton: 5128.78271484375, peak memory: 6682.23583984375, reserve: 7100.0
after backward allocaiton: 676.0498046875, peak memory: 5914.0458984375, reserve: 7100.0
before step allocaiton: 676.04931640625, peak memory: 676.05224609375, reserve: 7100.0
after step allocaiton: 676.04931640625, peak memory: 682.04931640625, reserve: 7100.0
